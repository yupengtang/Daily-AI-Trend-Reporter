---
layout: post
title: "Daily AI Research Papers - January 16, 2025"
date: 2025-01-16
---

**ðŸ”‘ Keywords**: open datasets, multi-modal retrieval, generative models, video generation, content generation, multimodal reasoning, music generation, visual perception, machine learning, private inference, image matching, zero-shot learning

**1. Towards Best Practices for Open Datasets for LLM Training**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.08365)  
ðŸ“‹ Summary: in countries like the EU and Japan, this is allowed
under certain restrictions, while in the United States, the legal landscape is
more ambiguous. Regardless of the legal status, concerns from creative
producers have led to several high-profile copyright lawsuits, and the threat
of litigation is commonly cited as a reason for the recent trend towards
minimizing the information shared about training datasets by both corporate and
public interest actors. This trend in limiting data information causes harm by
hindering transparency, accountability, and innovation in the broader ecosystem
by denying researchers, auditors, and impacted individuals access to the
information needed to understand AI models.
  While this could be mitigated by training language models on open access and
public domain data, at the time of writing, there are no such models (trained
at a meaningful scale) due to the substantial technical and sociological
challenges in assembling the necessary corpus. These challenges include
incomplete and unreliable metadata, the cost and complexity of digitizing
physical records, and the diverse set of legal and technical skills required to
ensure relevance and responsibility in a quickly changing landscape. Building
towards a future where AI systems can be trained on openly licensed data that
is responsibly curated and governed requires collaboration across legal,
technical, and policy domains, along with investments in metadata standards,
digitization, and fostering a culture of openness.

**2. MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.08828)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**3. CityDreamer4D: Compositional Generative Model of Unbounded 4D Cities**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.08983)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**4. RepVideo: Rethinking Cross-Layer Representation for Video Generation**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.08994)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**5. Ouroboros-Diffusion: Exploring Consistent Content Generation in
  Tuning-free Long Video Diffusion**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.09019)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**6. Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.09012)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**7. XMusic: Towards a Generalized and Controllable Symbolic Music Generation
  Framework**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.08809)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**8. Parameter-Inverted Image Pyramid Networks for Visual Perception and
  Multimodal Understanding**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.07783)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**9. Trusted Machine Learning Models Unlock Private Inference for Problems
  Currently Infeasible with Cryptography**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.08970)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**10. MINIMA: Modality Invariant Image Matching**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2412.19412)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">
