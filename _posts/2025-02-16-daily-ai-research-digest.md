---
layout: post
title: "Daily AI Research Papers - February 16, 2025"
date: 2025-02-16
---

**ðŸ”‘ Keywords**: stochastic models, large language models, text-to-image generation, 3D shape synthesis, zero-shot learning, self-supervised learning, multimodal models, context understanding, model adaptation, persona simulation, reasoning quality, benchmarking

**1. The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of
  Physical Concept Understanding**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.08946)  
ðŸ“‹ Summary: (1)\nstate-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag\nbehind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs,\nas they fail on our grid task but can describe and recognize the same concepts\nwell in natural language; (3) our task challenges the LLMs due to intrinsic\ndifficulties rather than the unfamiliar grid format, as in-context learning and\nfine-tuning on same formatted data added little to their performance.&quot;,&quot;upvotes&quot;:195,&quot;discussionId&quot;:&quot;67aeb181cb3be2cefd46ed4c&quot;,&quot;projectPage&quot;:&quot;https://physico-benchmark.github.io&quot;,&quot;githubRepo&quot;:&quot;https://github.com/physico-benchmark/physico&quot;,&quot;ai_summary&quot;:&quot;A study investigates whether large language models understand physical concepts through a grid-based task, showing that they significantly underperform compared to humans and highlighting the stochastic parrot phenomenon.&quot;,&quot;ai_keywords&quot;:[&quot;LLMs&quot;,&quot;Stochastic Parrot&quot;,&quot;PhysiCo&quot;,&quot;grid-format inputs&quot;,&quot;in-context learning&quot;,&quot;fine-tuning&quot;],&quot;githubStars&quot;:6},&quot;canReadDatabase&quot;:false,&quot;canManagePapers&quot;:false,&quot;canSubmit&quot;:false,&quot;hasHfLevelAccess&quot;:false,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;_id&quot;:&quot;6342796a0875f2c99cfd313b&quot;,&quot;avatarUrl&quot;:&quot;/avatars/98575092404c4197b20c929a6499a015.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Yuseung \&quot;Phillip\&quot; Lee&quot;,&quot;user&quot;:&quot;phillipinseoul&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;6683fc5344a65be1aab25dc0&quot;,&quot;avatarUrl&quot;:&quot;/avatars/e13cde3f87b59e418838d702807df3b5.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;hjkim&quot;,&quot;user&quot;:&quot;hojie11&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;64bba541da140e461924dfed&quot;,&quot;avatarUrl&quot;:&quot;/avatars/367993765b0ca3734b2b100db33ed787.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;zhijie deng&quot;,&quot;user&quot;:&quot;zhijie3&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;648eb1eb59c4e5c87dc116e0&quot;,&quot;avatarUrl&quot;:&quot;/avatars/c636cea39c2c0937f01398c94ead5dad.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;fdsqefsgergd&quot;,&quot;user&quot;:&quot;T-representer&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;66fffe1b3ec4cc293d40f2d5&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/66fffe1b3ec4cc293d40f2d5/-6Ff7rSQ_fvqBmTQRTlB4.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Micah Rentschler&quot;,&quot;user&quot;:&quot;micahr234&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;642bef38e8dfcc1fe4f60b38&quot;,&quot;avatarUrl&quot;:&quot;/avatars/7a6be4795bc34e118ae25cd8bf743628.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Jiahan Zhang&quot;,&quot;user&quot;:&quot;zonszer&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;60ab6b2ee3de7c7440abb845&quot;,&quot;avatarUrl&quot;:&quot;/avatars/22916bece3b5b951c016bf2ddd8dda1c.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Cindy&quot;,&quot;user&quot;:&quot;ttchungc&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;67af9705af830b220c1068d9&quot;,&quot;avatarUrl&quot;:&quot;/avatars/072e5b0dcd7a96a57d39f0cf62edbb6a.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mubai Luo&quot;,&quot;user&quot;:&quot;MiracBai&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;675c77f5d01f593dc901e2c6&quot;,&quot;avatarUrl&quot;:&quot;/avatars/c268723b8e47201cc60f6e3f8ddc4d8e.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Liu Yang&quot;,&quot;user&quot;:&quot;YangLiuWillow&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;67aa713d3f3906ccbf5380cb&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/3qDf_w_LbQcO_hUhhWEh-.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Kai Zhang&quot;,&quot;user&quot;:&quot;ChestnutKai&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;63fe24448b3c5087ff866b39&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/63fe24448b3c5087ff866b39/z8lI8NT7KMhDg8tLraAFp.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Shunchi Zhang&quot;,&quot;user&quot;:&quot;ShunchiZhang&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f3fd38c79c1ba4c353d041e&quot;,&quot;avatarUrl&quot;:&quot;/avatars/05964125a95808eb31bd106e51daec5b.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Wang Jiawei&quot;,&quot;user&quot;:&quot;JarvisMsra&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;acceptLanguages&quot;:[&quot;*&quot;],&quot;dailyPaperRank&quot;:1}">

**2. InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on
  a Single GPU**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.08910)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**3. Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient
  Text-to-Image Generation**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.08690)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**4. TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified
  Flow Models**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.06608)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**5. Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.09619)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**6. SelfCite: Self-Supervised Alignment for Context Attribution in Large
  Language Models**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.09604)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**7. EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language
  Models for Vision-Driven Embodied Agents**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.09560)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**8. An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in
  One Day via Model Merging**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.09056)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**9. CoSER: Coordinating LLM-Based Persona Simulation of Established Roles**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.09082)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**10. MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for
  Reasoning Quality, Robustness, and Efficiency**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2502.09621)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">
