---
layout: post
title: "Daily AI Research Papers - January 28, 2025"
date: 2025-01-28
---

**ðŸ”‘ Keywords**: Qwen2.5, Baichuan-Omni, Reinforcement Learning, RNN-Attention, Multilingual Dataset, ConvNet, Transformer, Language Models, Sparsity, Software Engineering, Vision Language Models, Multi-Modal Models

**1. Qwen2.5-1M Technical Report**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.15383)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**2. Baichuan-Omni-1.5 Technical Report**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.15368)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**3. Towards General-Purpose Model-Free Reinforcement Learning**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.16142)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**4. ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language
  Model Born from Transformer**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.15570)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**5. Emilia: A Large-Scale, Extensive, Multilingual, and Diverse Dataset for
  Speech Generation**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.15907)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**6. iFormer: Integrating ConvNet and Transformer for Mobile Application**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.15369)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**7. Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for
  Mixture-of-Experts Language Models**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.12370)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**8. CodeMonkeys: Scaling Test-Time Compute for Software Engineering**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.14723)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**9. Are Vision Language Models Texture or Shape Biased and Can We Steer
  Them?**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2403.09193)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">

**10. Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with
  Modality-Aware Sparsity**  
ðŸ”— [Read Paper](https://huggingface.co/papers/2501.16295)  
ðŸ“‹ Summary: border-blue-800 dark:bg-blue-900/15">
